\autoref{table:results} shows the results of the comparison in tabular format.
In the following sections, we will talk about each paper individually.

Each approach will be presented using five aspects:
\begin{enumerate}
	\item \textbf{Input} (e.g. source code or logs)
	\item \textbf{Approach} (how the extraction process works)
	\item \textbf{Output} (e.g. PCM or UML)
	\item \textbf{End user} (who the result is intended for)
	\item \textbf{Evaluation} (how were the results evaluated)
\end{enumerate}

\subsection{ARCHI4MOM}
\label{sec:Results:ARCHI4MOM}
\textbf{Input.}
The ARCHI4MOM approach extends the Performance Model Extraction (PMX) approach \cite{Walter2017PMX,Singh2022ARCHI4MOM} and therefore takes the same inputs.
The first step in the ARCHI4MOM approach is to instrument the source code with the Jaeger tracing tool \footnote{https://www.jaegertracing.io/} to collect tracing data.
Using the OpenTracing API, ARCHI4MOM then instruments all microservices to generate trace data, which can be used later to reconstruct the asynchronous communication between the microservices. \cite{Singh2022ARCHI4MOM} % TODO: Also supports MOM
\\ \\
\textbf{Approach.}
ARCHI4MOM extends the Performance Model Extraction (PMX) approach \cite{Walter2017PMX,Singh2022ARCHI4MOM} to support asynchronous communication.
This is achieved by adding a dependency to the OpenTracing API to each microservice to introduce a new set of information that was not present earlier \cite{Singh2022ARCHI4MOM}.
This tracing data is then collected in the form of JavaScript Object Notation (JSON) files, which become the input of the next phase \cite{Singh2022ARCHI4MOM}.

The JSON files will then be used to analyze the structure of the traces.
For message-based asynchronous communication, this presents a challenge since the information is distributed over different \textit{spans} whereas using synchronous communication, it would be in a single span \cite{Singh2022ARCHI4MOM}.
To match this inter-component communication using middleware, the called method needs to be matched using the OpenTracing API tags \cite{Singh2022ARCHI4MOM}.
In the next step, the ARCHI4MOM approach looks for send operations that do not have information about the topic \todo{explain} they send to and fills in this information by retrieving it from other send operations in the tracing data \cite{Singh2022ARCHI4MOM}.
Then the approach iterates over all sending spans that have a FOLLOWS-FROM or \textit{message-bus} relation \todo{explain} tag and propagate their topics to the receiving spans \cite{Singh2022ARCHI4MOM}.

To reconstruct message-based communication using PMX, the authors extended PMX to support the required Palladio Component Model elements \footnote{https://github.com/PalladioSimulator/Palladio-Addons-Indirections/tree/maste r/bundles/org.palladiosimulator.indirections/model}.
The authors then implement additional PMX logic to be able to reconstruct asynchronous architectures using these model elements.
\cite{Singh2022ARCHI4MOM}.
\\ \\
\textbf{Output.}
The output of the ARCHI4MOM approach is a Palladio Component Model (PCM) \cite{Singh2022ARCHI4MOM}.
This PCM contains the extracted components, as well as the interfaces for communication between each other \cite{Singh2022ARCHI4MOM}.
The communication channels are represented by \textit{DataChannel}s (representing the middleware) and \textit{DataInterface}s (representing the type of data the interface can send/receive), which are created in the PCM repository as part of the extraction \cite{Singh2022ARCHI4MOM}.
\\ \\
\textbf{End User.}
The output of the ARCHI4MOM approach is a PCM.
This model can then be used by software architects together with usage scenarios to create simulations, predicting the non-functional properties of the software.
\\ \\
\textbf{Evaluation.}
To evaluate the approach, the authors created a manual PCM of the Flowing Retail sample application \footnote{https://github.com/berndruecker/flowing-retail/tree/master/kafka/java}.
This manual model was then verified by three developers to be correct and compared to the automatically extracted model using a Goal Question Metric (GQM) plan \cite{VanSolingen2002GQM,Singh2022ARCHI4MOM}.
Using this plan, both sets of model elements (manual and automatic) are then compared using Precision, Recall and F1 score \cite{Singh2022ARCHI4MOM}.
The automatic approach achieved a precision score of 100\%, a recall score of 95.65\% and an F1 score of 97.8\% \cite{Singh2022ARCHI4MOM}. \todo{should I include the results or not?}

\subsection{MiSAR}
\label{sec:Results:MiSAR}
\textbf{Input.}
MiSAR extracts and gathers different data from static artifacts.
This data includes docker files that assemble the containers for the microservices, docker compose files that orchestrate multi-docker-container systems, java source code, maven pom.xml files, YAML configuration files, documentation and tool support \cite{Alshuqayran2018MiSAR}.
The java source code is reverse engineered using a tool called Enterprise architect \footnote{http://www.sparxsystems.com.au/products/ea/}, providing UML class diagrams from the source code \cite{Alshuqayran2018MiSAR}.
Additionally, Zipkin \footnote{https://zipkin.io} is used to trace communication between microservices to build a call graph \cite{Alshuqayran2018MiSAR}.
Information about latencies was retrieved using TCPDump \footnote{https://www.tcpdump.org} and information about the ports, IP addresses of container, and connectivity between containers were extracted using the Sysdig tool \footnote{https://github.com/draios/sysdig} \cite{Alshuqayran2018MiSAR}.
This information is all stored in a repository for further use.
\\ \\
\textbf{Approach.}
% TODO: Explain MDE, PIM, PSM; approach transforms from PSM to PIM using mapping rules
MiSAR is a manual approach that is executed in two phases \cite{Alshuqayran2018MiSAR}.
The first phase (Recovery Design, RD) defines architectural concepts, which are extracted in the second phase (Recovery Execution, RE) \cite{Alshuqayran2018MiSAR}.
\todo{extend}
\\ \\
\textbf{Output.}
\\ \\
\textbf{End User.}
\\ \\
\textbf{Evaluation.}

\subsection{--- \cite{Brosig2011}}
\label{sec:Results:Brosig}
\textbf{Input.}
The approach by Brosig et al. uses onlyl monitoring data collected at runtime to extract the effective architecture \cite{Israr2007interaction} of the system.
\\ \\
\textbf{Approach.}
% only considers parts effectively used at runtime
The approach presented by Brosig et al. only extracts the effective architecture \cite{Israr2007interaction} of the system, meaning that only parts that are effectively used at runtime are considered \cite{Brosig2011}.
The first step in the extraction of the effective architecture.
Before the extraction process can begin, component boundaries, which separate components as single entities from the point of view of the system's architect, need to be defined \cite{Brosig2011}.
This can be either done manually by a software architect or automatically using static code analysis \cite{Brosig2011}.
After the system boundaries have been determined, the running system is monitored using \textit{call path tracing} \cite{Brosig2011}.
The resulting \textit{event records} (representing entries or exists of components) are grouped together into \textit{call path event record sets} which contain event records that were triggered by the same system request \cite{Brosig2011}.
This data can then be used to obtain a call path \cite{Brosig2011} as well as a list of external services, a component's provided interface calls.
To extract an accurate representation of the system's components and connections between them, a representative usage profile has to be chosen, as the extraction only captures the actual communication that happens during the extraction approach \cite{Brosig2011}.
After the components and their connection have been extracted, the component-internal performance-relevant control flow has to be modeled.
This includes the internal behavior as well as the external service calls, the component makes \cite{Brosig2011}.

For the second step, the approach aims to extract model parameters for performance prediction \cite{Brosig2011}.
This is achieved by extracting branch probabilities and loop iteration numbers from the call paths \cite{Brosig2011}.
For branching probabilities, mean values are used, whereas loop iteration numbers are represented by a Probability Mass Function (PMF) to allow for accurate representation of cases where a loop is for example either executed twice or ten times \cite{Brosig2011}.
Next, the approach tries to quantify the resource demands (e.g. CPU, HDD) of the components' internal computations \cite{Brosig2011}.
This demand is represented by the total processing time minus the time spent waiting for the resource to become available \cite{Brosig2011}.
These parameters are then averaged over the observed call paths \cite{Brosig2011}.
The approach is also able to handle e.g. branches that depend on input parameter values \cite{Brosig2011}.
In this case, the dependency has to be known a-priori for the approach to quantify these dependencies \cite{Brosig2011}.

In the third step, the performance model is calibrated by comparing its predictions with measurements on the real system \cite{Brosig2011}.
The correction to be done when measuring a deviation between the prediction and the measurement is done by increasing a factor of overhead and accounting for delays produced by the middleware stack, the system runs on \cite{Brosig2011}.
% Continue reading Proof of Concept for more infos
\\ \\
\textbf{Output.}
% Output is PCM
The output of the approach by Brosig et al. is a performance model \cite{Brosig2011}.
In their proof-of-concept implementation, they generate a Palladio Component Model (PCM) \cite{Brosig2011}.
\\ \\
\textbf{End User.}
The end user for this approach is e.g. a software architect, which uses the performance model to predict software quality attributes.
\\ \\
\textbf{Evaluation.}
The evaluation of the approach was accomplished by implementing it and applying it to a case study of a Java Enterprise Edition application \cite{Brosig2011}.
The application used was the SPECjEnterprise2010 benchmark \footnote{https://www.spec.org/jEnterprise2010/}.


\subsection{MICROLYZE \cite{Kleehaus2018}}
\label{sec:Results:Microlyze}
\textbf{Input.}
Microlyze uses runtime data from a service discovery service, as well as manual inputs (e.g. semantic descriptions, mappings to technical requests) to reconstruct the software architecture \cite{Kleehaus2018}.
\\ \\
\textbf{Approach.}
% TODO: Business Process Modeller and Activity Mapper are controlled/fed by the user via a web interface
The Microlyze recovery approach is executed in six phases, which are meant to be executed continuously \cite{Kleehaus2018}.
The first phase rebuilds the current system architecture by checking a service discovery service (e.g., Eureka \footnote{https://github.com/Netflix/eureka} or Consul \footnote{https://www.consul.io}) and updating the status of the services in the current architecture \cite{Kleehaus2018}.

The second phase uses the IP addresses and ports retrieved from the service discovery service to establish a link between the services and the hardware used \cite{Kleehaus2018}.
Together with the IP addresses and ports, a monitoring agent has to be installed on each hardware component to retrieve additional information about the hardware \cite{Kleehaus2018}.
Additionally, a monitoring probe is installed on each microservice to observe the HTTP communication \cite{Kleehaus2018}.
The probe injects tracing data in the HTTP headers and therefore helps to gather timing data \cite{Kleehaus2018}.
The approach then collects additional infrastructure and software-specific data (e.g., endpoint name, class, method, HTTP request) and attaches this information as annotations \cite{Kleehaus2018}.
Using this data, the approach is then able to detect the dependencies between the microservices by following identifiers in the HTTP requests during runtime \cite{Kleehaus2018}.
This tracing is done using zipkin \footnote{https://github.com/openzipkin/zipkin}, streamed via apache kafka to Microlyze and then stored in a cassandra database \cite{Kleehaus2018}.
Microlyze additionally classifies each service on basis of the distributed tracing data \cite{Kleehaus2018}.
For example, if the first accessed microservice is identical in most requests, it is classified as a gateway service \cite{Kleehaus2018}.

In the third phase, all user transactions are stored in a database, including what the user does and in which order \cite{Kleehaus2018}.
These user transactions are then mapped to business transactions using a business process modeller \cite{Kleehaus2018}.
The information about the user transactions is used to create an association between the business transactions and the microservices that process these transactions \cite{Kleehaus2018}.

The fourth phase is responsible for defining semantic descriptions to each business activity, that can be performed by a user (e.g. \textit{register}, \textit{open shopping cart}, etc.) \cite{Kleehaus2018}.

After the business activities have been augmented with descriptions, phase five is able to create a mapping between the business activities (``a sequence of related events that together contribute to serve a user request'' \cite{Kleehaus2018}) and the technical requests extracted by zipkin \cite{Kleehaus2018}.
For this purpose, the authors enhanced the business process modeller with the regular expression language in order to describe technical requests \cite{Kleehaus2018}.
These regular expressions are stored in the database and matched on new incoming transactions to detect, if they might refer to an already modelled business activity \cite{Kleehaus2018}.

Finally, the sixth phase polls the service discovery service continuously to receive updates about unregistered or newly registered services \cite{Kleehaus2018}.
Services that are no longer registered are marked as such and unknown user requests that cannot be mapped to an existing business activity using the regular expressions are added to a list of unmapped URL endpoints \cite{Kleehaus2018}.
Changes to the underlying infrastructure are detected by changes in IP addresses or ports and lead to automatic adaptions in the architecture model \cite{Kleehaus2018}.
\\ \\
\textbf{Output.}
The results of the architecture extraction are displayed to the user as an adjacency matrix \cite{Kleehaus2018}.
\\ \\
\textbf{End User.}
The end users of the approach are administrators and enterprise or software architects \cite{Kleehaus2018}.
\\ \\
\textbf{Evaluation.}
To evaluate the appraoch, the authors developed a prototype and applied it to the TUM LLCM platform \footnote{https://www.cs.cit.tum.de/bpm/krcmar/research/finished-projects/tum-llcm-tum-living-lab-connected-mobility/} \cite{Kleehaus2018}.
They developed a service called \textit{Travelcompanion} which is meant to form travel groups to save on travel costs \cite{Kleehaus2018}.
To discover the relationships between the components, the authors produced traffic using JMeter \footnote{https://jmeter.apache.org} \cite{Kleehaus2018}.
After step three completed, the authors enhanced the technical transactions with a business semantic and mapped the business activities to user transactions \cite{Kleehaus2018}.
\subsection{--- \cite{Mayer2018}}
\label{sec:Results:Mayer}
\textbf{Input.}
The approach uses static information, provided by configuration files and static information about services (e.g., name, version, etc.) \cite{Mayer2018}.
Additionally, runtime communication between the microservices is collected and aggregated \cite{Mayer2018}.
\\ \\
\textbf{Approach.}
The approach presented by Mayer and Weinreich works in three steps, which are modeled by three main components \cite{Mayer2018}.
The first step---data collection---uses the \textit{Data Collection Library} to collect and provide static and runtime data for the architecture extraction components \cite{Mayer2018}.
This library collects and provides service-, interaction-, and infrastructure-related information using Swagger \footnote{https://swagger.io} to generate API descriptions and infrastructure-specific information providers (e.g., configuration files) that are configured by the user \cite{Mayer2018}.
The second step---data aggregation---uses the \textit{Aggregation Service} to aggregate the information collected in the first step \cite{Mayer2018}.
Lastly, the third step---data combination---uses the \textit{Management Service} combines the information from the different microservices and stores it in a data model \cite{Mayer2018}.

The authors also differentiate between three different kinds, or phases, of architecture extractions \cite{Mayer2018}.
The first phase is the static information extraction.
This extraction starts after a new service is deployed \cite{Mayer2018}.
Using swagger, a JSON representation of the service is sent to the \textit{Management Service}, which uses this information (namely the name and version of the service) to identify, whether the deployed service is a new instance of an already existing service, or a new service altogether \cite{Mayer2018}.
This phase of static architecture extraction finishes, by storing all static service information in the central \textit{Management Service} information database \cite{Mayer2018}.

The second phase concerns the extraction of infrastructure information \cite{Mayer2018}.
This phase builds on the information collected in the first phase and creates the according service instance node in the \textit{Management Service}'s database \cite{Mayer2018}.
This database is stored as a graph with directed edges, connecting the newly inserted service instance node to the necessary services and physical infrastructure information \cite{Mayer2018}.
If the nodes representing the physical infrastructure the service was deployed on (host and region) do not already exist, the \textit{Management Service} creates them.
As with the first phase, all information is stored in the information database at the end of the extraction \cite{Mayer2018}.

The third and last phase is responsible for extracting the runtime information.
For this purpose, all outgoing and incoming requests of a microservice are logged to a local file, including their timestamp, response time, response code, the ID of the source service instance, the URL of the target service instance, and the requested method \cite{Mayer2018}.
The \textit{Aggregation Service} consumes these log files periodically via REST interfaces and aggregates them \cite{Mayer2018}.
The aggregation condenses requests that have the same source and destination instance, the same method and the same response \cite{Mayer2018}.
The aggregated requests contain the time interval, the number of requests, and the average, maximum, and minimum response time \cite{Mayer2018}.
Lastly, these aggregated requests are then sent to the \textit{Management Service}, which stores them in its database \cite{Mayer2018}.
The \textit{Management Service} can also use this information to mark services as inactive, if it receives no runtime information anymore \cite{Mayer2018}.
\\ \\
\textbf{Output.}
The output of this approach is a database containing a directed graph that represents the system's architecture, as well as aggregated runtime information (e.g., response times) about the different requests \cite{Mayer2018}.
\\ \\
\textbf{End User.}
The end users of the output of this approach are architects, developers, and operation experts \cite{Mayer2018}.
\\ \\
\textbf{Evaluation.}
The authors conducted a combined survey and interview study (\cite{Mayer2017dashboard}) and used the feedback to construct a microservice dashboard that supports the different use cases identified by the survey \cite{Mayer2018}.
The authors then built a test scenario consisting of three microservices to test the long-term data collection capabilities of their approach \cite{Mayer2018}.

% TODO: Answer RQ!

% TODO: What is a tool/approach/... ? Define in paper

\begin{sidewaystable}
\centering
% check that total width matches
\resizebox{\textwidth}{!}{
%                 Name       Input    Approach Output   User     Eval     Year     Type
\begin{tabular}{| p{2.5cm} | p{2cm} | p{4cm} | p{2cm} | p{1.5cm} | p{4cm} | p{1cm} | p{1.2cm} |}
\toprule
\textbf{Name} & \textbf{Input} & \textbf{Approach} & \textbf{Output} & \textbf{End User} & \textbf{Evaluation} & \textbf{Year} & \textbf{Type} \\
\midrule
ARCHI4MOM (\cite{Singh2022ARCHI4MOM})
& source code
& Extend PMX to support asynchronous architectures
& PCM
& software architect
& Comparison with manual architecture
& 2022
& tool \\
\midrule
MiSAR (\cite{Alshuqayran2018MiSAR})
& source code, descriptive files, runtime traces
& manual extraction approach \todo{extend}
& 
& 
& 
& 2018
& manual approach \\
\midrule
--- (\cite{Brosig2011})
& run-time monitoring data
& combine an existing call path tracing and resource demand estimation to an end-to-end model extraction
& PCM
& 
& SPECjEnterprise2010 benchmark application; comparison of prediction with measurements
& 2011
& tool \\
\midrule
MICROLYZE (\cite{Kleehaus2018}) 
& monitoring data
& continuously monitor for system changes using a service discovery service; trace HTTP requests using zipkin
& database with services and their relations; web application to visualize as adjacency matrix
& system administrators and enterprise or software architects
& approach was applied to TUM LLCM platform, Travelcompanion service; traffic was generated and result was manually checked
& 2018
& tool \\
\midrule
--- (\cite{Mayer2018}) 
& static service information, infrastructure information and runtime logs
& condense static and dynamic information into single dimension to analyze the evolution over time; visualize information in dashboard
& aggregated data, visualized in dashboard
& 
& use tool in testing environment; check viability of results
& 2018
& tool \\
\bottomrule
\end{tabular}
}
\caption{Results} % TODO: Explanation text
\label{table:results}
\end{sidewaystable}
