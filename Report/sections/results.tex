We classify the available tools in 5 categories.
The classification results are presented in \autoref{table:results}.

Each approach will be presented using five aspects:
\begin{enumerate}
	\item \textbf{Input} (the input of the reverse engineering approach) \\
		  There can be many inputs to an RE extraction approach.
		  The inputs can be static information, like the source code of the software-system, Docker configuration files and documentation.
		  In the case of a dynamic approach, the input is dynamic data, like runtime logs, communication tracing information or a list of registered services from a service discovery service.
	\item \textbf{Approach} (how the extraction process works) \\
	      RE extraction approaches are classified into three categories.
	      Static approaches only use static data (e.g., source code, configuration files) and do not require the system to be executed to extract the architecture.
	      Dynamic approaches on the other hand, only use runtime data (e.g., logs, service discovery service responses) to analyze the software-system's architecture.
	      In between, there are hybrid approaches that use both static and dynamic data to analyze the system.
	      These hybrid approaches detect the registered components statically from the source code and then monitor the runtime communication data to recognize the relationships between the components.
	\item \textbf{Output} (the expected output format of the RE extraction approach) \\
	      The output of the RE extraction approach is used by the software architect or developer.
	      Depending on the requirement, the output can have different formats.
	      For example, an approach could simply output an adjacency matrix, showing which components communicate with which other components.
	      A more complex output could be an UML diagram, depicting the components and their relationships graphically or even a web interface showing aggregated data about the analyzed system.
	      Another possible output is a performance model or a database.
	\item \textbf{End user} (the intended stakeholder of the RE extraction result) \\
		  Typically the software architect or the developer are the intended end users of the extracted architecture.
		  In the case of an UML diagram, a developer could use the output to understand the system.
  		  With a performance model on the other hand, a software architect can predict the software-quality at design time.
	\item \textbf{Evaluation} (the evaluation of the extracted results of the RE extraction approaches) \\
		  Lastly, we will look at how the different approaches were evaluated.
		  Examples for evaluation approaches include Precision/Recall/F1 calculation or the manual comparison of the extracted architecture with the documentation.
		  We will only focus on how the evaluation was performed and not on the results of the evaluation.
\end{enumerate}


%%%%%%%%%%%%%
% ARCHI4MOM %
%%%%%%%%%%%%%
\subsection{ARCHI4MOM}
\label{sec:Results:ARCHI4MOM}
\textbf{Input.}
The ARCHI4MOM approach extends the Performance Model Extraction (PMX) approach \cite{Walter2017PMX,Singh2022ARCHI4MOM} and therefore takes source code as the input.
The first step in the ARCHI4MOM approach is to instrument the source code with the Jaeger tracing tool \cite{Jaeger} to collect tracing data.
Using the OpenTracing API, ARCHI4MOM then instruments all microservices to generate trace data, which can be used later to reconstruct the asynchronous communication between the microservices. \cite{Singh2022ARCHI4MOM}
\\ \\
\textbf{Approach.}
ARCHI4MOM extends the PMX approach \cite{Walter2017PMX,Singh2022ARCHI4MOM} to support asynchronous communication.
This is achieved by adding a dependency to the OpenTracing API to each microservice to introduce a new set of information that was not present earlier \cite{Singh2022ARCHI4MOM}.
This tracing data is then collected in the form of JavaScript Object Notation (JSON) files, which become the input of the next phase \cite{Singh2022ARCHI4MOM}.

We then analyze the structure of the traces using the JSON files.
For message-based asynchronous communication, this presents a challenge because the information is distributed over different parts of the tracing data (called ``spans'') whereas using synchronous communication, it would be in a single span \cite{Singh2022ARCHI4MOM}.
To match this inter-component communication using middleware, the called method needs to be matched using tags provided by the OpenTracing API \cite{Singh2022ARCHI4MOM}.
In the next step, the ARCHI4MOM approach looks for send operations that do not have information about the topic they send to \cite{Singh2022ARCHI4MOM}.
A topic in this case is something a receiver can subscribe to \cite{Singh2022ARCHI4MOM}.
After subscribing to a topic, the subscriber then receives all messages that are sent to that topic \cite{Singh2022ARCHI4MOM}.
ARCHI4MOM then fills in the missing topic information by retrieving it from other send operations in the tracing data \cite{Singh2022ARCHI4MOM}.
Then the approach iterates over all sending spans that have a ``FOLLOWS-FROM'' or ``\textit{message-bus}'' relation tag and propagate their topics to the receiving spans \cite{Singh2022ARCHI4MOM}.

To reconstruct message-based communication using PMX, the authors extended PMX to support the desired Palladio Component Model elements \footnote{https://github.com/PalladioSimulator/Palladio-Addons-Indirections/tree/maste r/bundles/org.palladiosimulator.indirections/model}.
The authors then implement additional PMX logic to be able to reconstruct asynchronous architectures using these model elements.
\cite{Singh2022ARCHI4MOM}.
\\ \\
\textbf{Output.}
The output of the ARCHI4MOM approach is an instance of the Palladio Component Model (PCM) \cite{Singh2022ARCHI4MOM}.
This PCM contains the extracted components, as well as the interfaces for communication between each other \cite{Singh2022ARCHI4MOM}.
The communication channels are represented by \textit{DataChannel}s (representing the topics or message queues) and \textit{DataInterface}s (representing the type of data the interface can send/receive), which the approach creates in the PCM repository as part of the extraction \cite{Singh2022ARCHI4MOM}.
\\ \\
\textbf{End User.}
The ARCHI4MOM approach generates an instance of the PCM.
This model can then be used by software architects together with usage scenarios to predict the performance of the system during design time.
\\ \\
\textbf{Evaluation.}
To evaluate the approach, the authors created a manual PCM model of a sample application, which was then verified by three developers to be correct and compared to the automatically extracted model using a Goal Question Metric (GQM) plan \cite{VanSolingen2002GQM,Singh2022ARCHI4MOM}.
Using this plan, the authors then compare both sets of model elements (manual and automatic) using Precision, Recall and F1 score \cite{Singh2022ARCHI4MOM}.


%%%%%%%%%
% MiSAR %
%%%%%%%%%
\subsection{MiSAR}
\label{sec:Results:MiSAR}
\textbf{Input.}
MiSAR extracts and gathers different data from static artifacts.
This data includes Docker files that assemble the containers for the microservices, Docker compose files that orchestrate multi-Docker-container systems, Java source code, Maven pom.xml files, YAML configuration files, documentation and tool support \cite{Alshuqayran2018MiSAR}.
The approach reverse engineers Java source code using a tool called Enterprise Architect \cite{EnterpriseArchitect}, providing UML class diagrams from the source code \cite{Alshuqayran2018MiSAR}.
Additionally, it uses Zipkin \cite{Zipkin} to trace communication between microservices to build a call graph \cite{Alshuqayran2018MiSAR}.
The approach retrieves information about latencies using TCPDump \cite{TCPDump} and extracts information about the ports, IP addresses of container, and connectivity between containers using the Sysdig tool \cite{Sysdig} \cite{Alshuqayran2018MiSAR}.
This information is all stored in a repository for further use.
\\ \\
\textbf{Approach.}
MiSAR is a static and manual architecture extraction approach that is executed in two phases \cite{Alshuqayran2018MiSAR}.
The first phase (Recovery Design, RD) defines architectural concepts, which are extracted in the second phase (Recovery Execution, RE) \cite{Alshuqayran2018MiSAR}.

Phase 1 is executed in six steps.
The first step is responsible for collecting the required input data, including the source code, configuration files, descriptive files etc. \cite{Alshuqayran2018MiSAR}.
After all data has been collected, it is stored in a repository \cite{Alshuqayran2018MiSAR}.

In step 2, the collected data is analyzed and combined \cite{Alshuqayran2018MiSAR}.
The authors extract a static view of the system in form of UML class diagrams by using the reverse engineering tool Enterprise Architect on the source code \cite{Alshuqayran2018MiSAR}.
Additionally, the system is observed during runtime to perform a dynamic analysis \cite{Alshuqayran2018MiSAR}.
For this purpose, Zipkin is used to trace the communication between the different components \cite{Alshuqayran2018MiSAR}.
TCPDump and the Sysdig tool are used to measure the latencies of the communication and performance diagnostics at container level, respectively \cite{Alshuqayran2018MiSAR}.

The extracted information is combined with the gathered information from step 1 and is then used in the third step to determine the architectural concepts.
This step focuses on bottom-up (from code to model) and top-down (from model to code) analysis to identify the architectural concepts used \cite{Alshuqayran2018MiSAR}.

The next step, step 4, then defines the architectural concerns \cite{Alshuqayran2018MiSAR}.
A concern is an area of interest with respect to a software design \cite{SWEBOK}.
In the case of microservices, they represent common characteristics that can be implemented across multiple services \cite{Alshuqayran2018MiSAR}.
As these concerns are different to identify from just the code, the authors try to identify technologies that are commonly used to implement concerns that the approach already knows \cite{Alshuqayran2018MiSAR}.
For this purpose, the authors have selected the most commonly used concerns from literature \cite{Alshuqayran2018MiSAR}.

The identified concerns are then grouped together in step 5, based on high level concerns that the authors have identified \cite{Alshuqayran2018MiSAR}.

In the last step of phase 1, the authors look at the files that were extracted for each concept and analyze them \cite{Alshuqayran2018MiSAR}.
Using these files, the authors defined mapping rules that map the architectural concepts to the implementation artifacts \cite{Alshuqayran2018MiSAR}.
They then classified and grouped these mapping rules based on the architectural element, they output \cite{Alshuqayran2018MiSAR}.

Finally, in phase 2, the identified architectural concepts are extracted using the mapping rules.
The person executing the approach validates the results and refines the mapping rules manually, leading to an iterative process of executing phase 2 with the improved mapping rules \cite{Alshuqayran2020Thesis}.
This process is repeated until the output is sufficient \cite{Alshuqayran2020Thesis}.
\\ \\
\textbf{Output.}
The output of MiSAR is an instance diagram equivalent to an UML object diagram \cite{Alshuqayran2020Thesis}.
The diagram conforms to the Platform Independent Model (PIM) metamodel, which is a specific set of rules and guidelines for creating models that can be used to describe systems in a platform-agnostic way \cite{PIM}.
\\ \\
\textbf{End User.}
The intended end user of this approach are the software architects that can use the architecture model to understand and refine the system.
\\ \\
\textbf{Evaluation.}
The approach was evaluated  by comparing the output of the approach to the documentation of the actual system architecture \cite{Alshuqayran2020Thesis}.
The system the authors used for evaluation was TrainTicket \cite{Zhou2018TrainTicket}, a benchmarking system that already provided extensive documentation about the system architecture.
The authors measure the deviations from the documentation, additional elements and missing elements and calculated the Precision, Recall and F1-Score to quantify their approach \cite{Alshuqayran2020Thesis}.


%%%%%%%%%%
% Brosig %
%%%%%%%%%%
\subsection{Approach by Brosig et al.}
\label{sec:Results:Brosig}
\textbf{Input.}
The approach by Brosig et al. uses monitoring data collected at runtime to extract the effective architecture \cite{Israr2007interaction} of the system.
For the detection of the component boundaries, the approach uses either static code analysis on the source code, or a software architect can manually define the boundaries \cite{Brosig2011}.
\\ \\
\textbf{Approach.}
% only considers parts effectively used at runtime
The approach presented by Brosig et al. only extracts the effective architecture \cite{Israr2007interaction} of the system, meaning that only parts that are effectively used at runtime during the extraction are considered \cite{Brosig2011}.
Component communication can only be extracted, if the specific components actually communicate during the extraction approach.
The first step is the extraction of the effective architecture.
Before the extraction process can begin, component boundaries, which separate components as single entities from the point of view of the system's architect, need to be defined \cite{Brosig2011}.
This can be either done manually by a software architect or automatically using static code analysis \cite{Brosig2011}.
After the system boundaries have been determined, the running system is monitored and the communication between the components is traced \cite{Brosig2011}.
The resulting \textit{event records} (representing entries or exits of components) are grouped together into \textit{call path event record sets} which contain event records that were triggered by the same system request \cite{Brosig2011}.
This data is then used to obtain a call path \cite{Brosig2011} as well as a list of external services, a component's provided-interface calls.
To extract an accurate representation of the system's components and connections between them, a representative usage profile has to be chosen, as the extraction only captures the actual communication that happens during the extraction approach \cite{Brosig2011}.
After the components and their connection have been extracted, the component-internal performance-relevant control flow has to be modeled.
This includes the internal behavior as well as the external service calls, the component makes \cite{Brosig2011}.

For the second step, the approach aims to extract model parameters for performance prediction \cite{Brosig2011}.
This is achieved by extracting branch probabilities and loop iteration numbers from the call paths \cite{Brosig2011}.
For branching probabilities, mean values are used, whereas loop iteration numbers are represented by a Probability Mass Function (PMF) to allow for accurate representation of cases where a loop is, for example, either executed twice or ten times \cite{Brosig2011}.
Next, the approach tries to quantify the resource demands (e.g. CPU, HDD) of the components' internal computations \cite{Brosig2011}.
This demand is represented by the total processing time minus the time spent waiting for the resource to become available \cite{Brosig2011}.
These parameters are then averaged over the observed call paths \cite{Brosig2011}.
The approach is also able to handle e.g. branches that depend on input parameter values \cite{Brosig2011}.
In this case, the dependency has to be known a-priori for the approach to quantify these dependencies \cite{Brosig2011}.

In the third step, the performance model is calibrated by comparing its predictions with measurements on the real system \cite{Brosig2011}.
The correction to be done when measuring a deviation between the prediction and the measurement is done by increasing a factor of overhead and accounting for delays produced by the middleware stack, the system runs on \cite{Brosig2011}.
\\ \\
\textbf{Output.}
The output of the approach by Brosig et al. is a performance model \cite{Brosig2011}.
As a proof-of-concept implementation, they generate a Palladio Component Model (PCM) instance \cite{Brosig2011}.
\\ \\
\textbf{End User.}
The end user for this approach is e.g. a software architect, which uses the performance model to predict software performance and other quality attributes.
\\ \\
\textbf{Evaluation.}
The evaluation of the approach was accomplished by implementing it and applying it to a case study of a Java Enterprise Edition application \cite{Brosig2011}.
The case study application used was the SPECjEnterprise2010 benchmark \cite{SPECjEnterprise2010}.


%%%%%%%%%%%%%
% MICROLYZE %
%%%%%%%%%%%%%
\subsection{MICROLYZE}
\label{sec:Results:Microlyze}
\textbf{Input.}
Microlyze uses runtime data from a service discovery service, as well as manual inputs (e.g. semantic descriptions, mappings to technical requests) to reconstruct the software architecture \cite{Kleehaus2018}.
\\ \\
\textbf{Approach.}
The Microlyze recovery approach is executed in six phases, which are meant to be executed continuously \cite{Kleehaus2018}.
The first phase rebuilds the current system architecture by checking a service discovery service (e.g., Eureka \cite{Eureka} or Consul \cite{Consul}) and updating the status of the services in the current architecture \cite{Kleehaus2018}.

The second phase uses the IP addresses and ports retrieved from the service discovery service to establish a link between the services and the hardware used \cite{Kleehaus2018}.
Together with the IP addresses and ports, the approach installs monitoring agent on each hardware component to retrieve additional information about the hardware \cite{Kleehaus2018}.
Additionally, it installs a monitoring probe on each microservice to observe the HTTP communication \cite{Kleehaus2018}.
The probe injects tracing data in the HTTP headers and therefore helps to gather timing data \cite{Kleehaus2018}.
The approach then collects additional infrastructure and software-specific data (e.g., endpoint name, class, method, HTTP request) and attaches this information as annotations \cite{Kleehaus2018}.
Using this data, the approach is then able to detect the dependencies between the microservices by following identifiers in the HTTP requests during runtime \cite{Kleehaus2018}.
This tracing is done using Zipkin, streamed via apache kafka to Microlyze and then stored in a cassandra database \cite{Kleehaus2018}.
Microlyze additionally classifies each service on basis of the distributed tracing data \cite{Kleehaus2018}.
For example, if the first accessed microservice is identical in most requests, it is classified as a gateway service \cite{Kleehaus2018}.

In the third phase, Microlyze stores all user transactions in a database, including what the user does and in which order \cite{Kleehaus2018}.
It then maps these user transactions to business transactions using a business process modeller \cite{Kleehaus2018}.
This mapping is done by the user via a web interface \cite{Kleehaus2018}.
The information about the user transactions is used to create an association between the business transactions and the microservices that process these transactions \cite{Kleehaus2018}.

The fourth phase is responsible for defining semantic descriptions to each business activity, that can be performed by a user (e.g. \textit{register}, \textit{open shopping cart}, etc.) \cite{Kleehaus2018}.

After a user has augmented the business activities with descriptions, phase five is able to create a mapping between the business activities (``a sequence of related events that together contribute to serve a user request'' \cite{Kleehaus2018}) and the technical requests extracted by Zipkin \cite{Kleehaus2018}.
For this purpose, the authors enhanced the business process modeler with the regular expression language in order to describe technical requests \cite{Kleehaus2018}.
These regular expressions are stored in the database and matched on new incoming transactions to detect, if they might refer to an already modeled business activity \cite{Kleehaus2018}.

Finally, the sixth phase polls the service discovery service continuously to receive updates about unregistered or newly registered services \cite{Kleehaus2018}.
Microlyze marks services that are no longer registered as such and adds unknown user requests that cannot be mapped to an existing business activity using the regular expressions to a list of unmapped URL endpoints \cite{Kleehaus2018}.
It detects changes to the underlying infrastructure by changes in IP addresses or ports \cite{Kleehaus2018}.
Those changes lead to automatic adaptions in the architecture model \cite{Kleehaus2018}.
\\ \\
\textbf{Output.}
The approach displays the results of the architecture extraction via a web interface to the user as an adjacency matrix \cite{Kleehaus2018}.
\\ \\
\textbf{End User.}
The end users of the approach are administrators and enterprise or software architects \cite{Kleehaus2018}.
\\ \\
\textbf{Evaluation.}
To evaluate the approach, the authors developed a prototype and applied it to the TUM LLCM platform \cite{TUMLLCM} \cite{Kleehaus2018}.
They developed a service called \textit{Travelcompanion} which is meant to form travel groups to save on travel costs \cite{Kleehaus2018}.
To discover the relationships between the components, the authors produced traffic using JMeter \cite{JMeter} \cite{Kleehaus2018}.
After step three completed, the authors enhanced the technical transactions with a business semantic and mapped the business activities to user transactions \cite{Kleehaus2018}.

%%%%%%%%%%%%%%%%%%%%
% Mayer, Weinreich %
%%%%%%%%%%%%%%%%%%%%
\subsection{Approach by Mayer and Weinreich}
\label{sec:Results:Mayer}
\textbf{Input.}
The approach uses static information from configuration files and static information about services (e.g., name, version, etc.) \cite{Mayer2018}.
Additionally, runtime communication between the microservices is collected and aggregated \cite{Mayer2018}.
\\ \\
\textbf{Approach.}
The approach presented by Mayer and Weinreich works in three steps, which are modeled by three main components \cite{Mayer2018}.
The first step---data collection---uses the \textit{Data Collection Library} to collect and provide static and runtime data for the architecture extraction components \cite{Mayer2018}.
This library collects and provides service-, interaction-, and infrastructure-related information using Swagger \cite{Swagger} to generate API descriptions and infrastructure-specific information providers (e.g., configuration files) that are configured by the user \cite{Mayer2018}.
The second step---data aggregation---uses the \textit{Aggregation Service} to aggregate the information collected in the first step \cite{Mayer2018}.
Lastly, the third step---data combination---uses the \textit{Management Service} to combine the information from the different microservices and store it in a data model \cite{Mayer2018}.

The authors also differentiate between three different kinds, or phases, of architecture extraction \cite{Mayer2018}.
The first phase is the static information extraction.
This extraction starts after a new service is deployed \cite{Mayer2018}.
Using swagger, the approach sends a JSON representation of the service to the \textit{Management Service}, which uses this information (namely the name and version of the service) to identify, whether the deployed service is a new instance of an already existing service, or a new service altogether \cite{Mayer2018}.
This phase of static architecture extraction finishes, by storing all static service information in the central \textit{Management Service} information database \cite{Mayer2018}.

The second phase concerns the extraction of infrastructure information \cite{Mayer2018}.
This phase builds on the information collected in the first phase and creates the according service instance node in the \textit{Management Service}'s database \cite{Mayer2018}.
It then stores this database as a graph with directed edges, connecting the newly inserted service instance node to the necessary services and physical infrastructure information \cite{Mayer2018}.
If the nodes representing the physical infrastructure the service was deployed on (host and region) do not already exist, the \textit{Management Service} creates them.
As with the first phase, the approach stores all information in the information database at the end of the extraction \cite{Mayer2018}.

The third and last phase is responsible for extracting the runtime information.
For this purpose, the approach logs all outgoing and incoming requests of a microservice to a local file, including their timestamp, response time, response code, the ID of the source service instance, the URL of the target service instance, and the requested method \cite{Mayer2018}.
The \textit{Aggregation Service} consumes these log files periodically via REST interfaces and aggregates them \cite{Mayer2018}.
The aggregation condenses requests that have the same source and destination instance, the same method and the same response \cite{Mayer2018}.
The aggregated requests contain the time interval, the number of requests, and the average, maximum, and minimum response time \cite{Mayer2018}.
Lastly, the Aggregation Service sends these aggregated requests to the \textit{Management Service}, which stores them in its database \cite{Mayer2018}.
The \textit{Management Service} can also use this information to mark services as inactive, if it receives no runtime information anymore \cite{Mayer2018}.
\\ \\
\textbf{Output.}
The output of this approach is a database containing a directed graph that represents the system's architecture \cite{Mayer2018}.
The graph is annotated with aggregated runtime information (e.g., response times) about the different requests \cite{Mayer2018}.
This information is visualized in a web interface.
\\ \\
\textbf{End User.}
The end users of the output of this approach are architects, developers, and operation experts \cite{Mayer2018}.
\\ \\
\textbf{Evaluation.}
The authors conducted a combined survey and interview study (\cite{Mayer2017dashboard}) and used the feedback to construct a microservice dashboard that supports the different use cases identified by the survey \cite{Mayer2018}.
The authors then built a test scenario consisting of three microservices to test the long-term data collection capabilities of their approach \cite{Mayer2018}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Answering the Guiding Questions %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Answering the Guiding Questions}
\label{sec:Results:AnsweringRQ}

In this section, we briefly discuss the results obtained from our guiding questions.

\subsubsection{Question 1}
\textbf{What are the tools available for the extraction of asynchronous architectures of microservice systems?}
\\ \\
In the previous sections, we presented five approaches for the architecture extraction of microservice systems.
Each of these systems is able to handle asynchronous REST communication and in the case of \cite{Singh2022ARCHI4MOM,Alshuqayran2018MiSAR,Brosig2011}, the approaches also support the extraction of message-based asynchronous communication architectures as described in \autoref{sec:Foundation:AsyncCommunication:MBC}.

\subsubsection{Question 2}
\textbf{To what extend do these tools support asynchronous software architecture extraction?}
\\ \\
The extend to which the approaches support the extraction of asynchronous architectures differs.

ARCHI4MOM \cite{Singh2022ARCHI4MOM}, MiSAR \cite{Alshuqayran2018MiSAR} and the approach presented by Brosig \cite{Brosig2011} all support the extraction of architectures using message-based asynchronous communication.

Due to the manual nature of the extraction approach, the MiSAR approach is very flexible and as the mapping rules are formulated in natural language \cite{Alshuqayran2020Thesis}, it is possible to intervene and tweak rules that do not recover the correct architecture.
The approach results in an architectural model that visualizes via a diagram the architecture of the system.

The approach presented by Brosig et al. presents an end-to-end model extraction that results in a performance model \cite{Brosig2011}.
Their proof-of-concept implementation showed, that it is possible to extract full Palladio Component Models, including usage models \cite{Brosig2011}.

The MICROLYZE approach is meant to be used continuously, which means it will be invoked on every change to the code or architecture, thus resulting in an up-to-date performance model of the system.
Due to the fact that MICROLYZE keeps the architecture model data in a database, the architecture does not have to be extracted anew each time, a part of the system changes.

The approach of Mayer and Weinreich is also meant to be used continuously and also holds model data in a database to be able to persist information between invocations.
The results are visualized in a web interface that aggregates the data and displays it in a way for anyone to understand it.
\\

\textbf{Limitations.}
ARCHI4MOM is limited in the types of asynchronous microservice software systems it can process.
ARCHI4MOM does not support mixed-technology systems where both synchronous as well as asynchronous communication is used \cite{Singh2022ARCHI4MOM}.
Additionally, ARCHI4MOM only extracts the repository and part of the system model of the PCM.

The MiSAR approach is a manual approach and therefore not suited to be used in an continuous and automated environment.
It has to be executed by a human, since the mapping rules are formulated in natural language. \cite{Alshuqayran2018MiSAR}

The approach presented by Brosig et al. only considers the effective architecture of the system.
Parts of the system that are not used during runtime are not represented in the resulting Palladio Component Model. \cite{Brosig2011}

A limitation of the MICROLYZE approach is that is requires a service discovery service to be present to fully work \cite{Kleehaus2018}.
Another drawback is that MICROLYZE is only able to extract the architecture of software systems using asynchronous HTTP REST communication.
It does not support message-based communication.

The approach by Mayer and Weinreich also only supports HTTP REST communication.


%%%%%%%%%
% Table %
%%%%%%%%%
\begin{sidewaystable}
\centering
\resizebox{\textwidth}{!}{
%                 Name       Input    Approach Output   User     Eval     Year     Type
\begin{tabular}{| p{2.5cm} | p{2cm} | p{4cm} | p{2cm} | p{1.8cm} | p{4cm} | p{1cm} | p{3cm} |}
\hline
\textbf{Name} & \textbf{Input} & \textbf{Approach} & \textbf{Output} & \textbf{End User} & \textbf{Evaluation} & \textbf{Year} & \textbf{Type} \\
\hline
ARCHI4MOM (\cite{Singh2022ARCHI4MOM})
& Tracing data produced by jaeger
& Extend PMX to support asynchronous architectures
& PCM (repository and part of system model)
& Software architect
& Comparison with manual architecture
& 2022
& Approach and Implementation (HTTP or message-based) \\
\hline
MiSAR (\cite{Alshuqayran2018MiSAR})
& Source code, descriptive files, runtime traces
& Create and apply mapping rules manually
& Instance diagram
& Software architect
& Comparison with existing documentation
& 2018
& Manual approach (HTTP or message-based) \\
\hline
Approach by Brosig (\cite{Brosig2011})
& Runtime monitoring data
& Combine call path tracing and resource demand estimation
& Full PCM
& Software architect
& Comparison with SPECjEnterprise2010 benchmark application
& 2011
& Automated approach (HTTP or message-based) \\
\hline
MICROLYZE (\cite{Kleehaus2018}) 
& Manual inputs and Monitoring Data
& Trace HTTP requests, store in DB, map transactions and monitor system for changes
& Adjacency matrix
& System administrators and enterprise or software architects
& Manual Comparison with TUM LLCM
& 2018
& Approach (only HTTP) \\
\hline
Approach by Mayer and Weinreich (\cite{Mayer2018}) 
& Static, infrastructure and runtime information
& Condense static and dynamic information into single dimension
& Aggregated data, visualized in dashboard
& Anyone
& Check viability of test results
& 2018
& Approach (only HTTP) \\
\hline
\end{tabular}
}
\caption{Results}
\label{table:results}
\end{sidewaystable}